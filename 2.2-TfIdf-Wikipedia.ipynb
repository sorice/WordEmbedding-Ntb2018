{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tf-Idf with Wikipedia\n",
    "\n",
    "*Gensim, Scipy, Sklearn software examples.*\n",
    "\n",
    "**Note**: The next sample codes are made using the data obtained after the transformation of Wikipedia dump with `gensim.scripts.make_wikicorpus.py` methods to converted it to Bag of Word model.\n",
    "\n",
    "**Prerequisites:** Skills in tokenization with nltk, knowledge of Word2Vec Text Representation model.\n",
    "\n",
    "## Outline\n",
    "\n",
    "**Main Goal:** To practice how to create _tfidf_ model using Wikipedia corpus. As previous notebook the roadmap it is generate de model, then learn how to extract information from it, and finally how to measure word similarity using the model as base.\n",
    "\n",
    "- Wrangling Data to init the model generation\n",
    "- Gensim Corpus Inizialization\n",
    "- TfIdf model example generation/loading\n",
    "- Text similarity measures examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TfidfModel\n",
    "from gensim.corpora import TextCorpus, MmCorpus, Dictionary\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_path = '/media/DATA/wiki_es/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Acquiring & Wrangling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Text does not contain num_docs on the first line.\n"
     ]
    }
   ],
   "source": [
    "#Loading resources generated priviously with Gensim package\n",
    "dictionary = Dictionary.load_from_text(corpus_path+'_wordids.txt.bz2')\n",
    "bow_corpus = MmCorpus(corpus_path+'_bow.mm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Generating the Tf-Idf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfIdf Model Generated in 658.466673374176 seconds\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tfidf =TfidfModel.load(corpus_path+'wiki-tfidf.model')\n",
    "    print('TfIdf Model Generated in 658.466673374176 seconds')\n",
    "except:\n",
    "    init = time.time()\n",
    "    tfidf = TfidfModel(bow_corpus,dictionary)\n",
    "    end = time.time()-init\n",
    "    print(end)\n",
    "    tfidf._smart_save(corpus_path+'wiki-tfidf.model')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After 11 minutes my 1stG-i7 laptop, 8Gb RAM, finish the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the word with index 1000 in the dictionary\n",
    "print(dictionary[1000])\n",
    "\n",
    "#print the bow vector of the sentence 1\n",
    "sent = \"Yo como pescado\"\n",
    "vec_sent = dictionary.doc2bow(sent.lower().split())\n",
    "print(vec_sent)\n",
    "\n",
    "#print the TFIDF vector of the sentence 1\n",
    "vec_sent_tfidf = tfidf[vec_sent]\n",
    "print(vec_sent_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Measuring Similarity between Pair of Sentences\n",
    "\n",
    "This section is made to show the utility of _tfidf model in an applied example. Also to show some native similarity methods of `gensim.model.TfIdfModel` class.\n",
    "\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(11023, 0.4817709603680243), (20504, 0.5599326515327857), (28174, 0.35634410125465255), (46995, 0.5721809582593161)]\n",
      "[(28174, 0.49053568087890215), (46995, 0.787652089532131), (72558, 0.3727987817044736)]\n"
     ]
    }
   ],
   "source": [
    "sentence1 = 'the girl run into the hall'\n",
    "sentence2 = 'Here Alice run to the hall'\n",
    "\n",
    "sent1 = sentence1.lower().split()\n",
    "sent2 = sentence2.lower().split()\n",
    "\n",
    "sentence1_ws = 'girl run hall'\n",
    "sentence2_ws = 'Alice run hall'\n",
    "\n",
    "sent1s = sentence1_ws.lower().split()\n",
    "sent2s = sentence2_ws.lower().split()\n",
    "\n",
    "#If we change the sent1 by a very different meaning sent3\n",
    "sent3 = ['the','boy','eat','a','red','apple']\n",
    "sent3s = ['boy','eat','red','apple']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Wrangling Data\n",
    "\n",
    "* First: From string-sentences to bow representation of a sentence.\n",
    "* Second: From bow representation to numerical-list representation of a sentence.\n",
    "* Third: From numerical-list vector to numerical-vector (numpy) representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_sent1 = dictionary.doc2bow(sentence1)\n",
    "vec_sent2 = dictionary.doc2bow(sentence2)\n",
    "\n",
    "vec_sent1_tfidf = tfidf[vec_sent1]\n",
    "vec_sent2_tfidf = tfidf[vec_sent2]\n",
    "\n",
    "print(vec_sent1_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Sklearn TfIdf-Cosine sentence similarity\n",
    "\n",
    "The last experiment is made with TfIdf matrix from gensim.\n",
    "Unfortunately to load the Wikipedia dump to make a tf-idf index is to much for this computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5773502691896258"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from textsim.tokendists import cosine_similarity_sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#Sklearn cosine for raw sentences implemented in textsim\n",
    "cosine_similarity_sklearn(sent1,sent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625479023699579"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.asarray(nvec1).reshape((1,-1))\n",
    "B = np.asarray(nvec2).reshape((1,-1))\n",
    "cosine_similarity(A,B)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Scipy TfIdf-Cosine sentence similarity\n",
    "\n",
    "Testing similarity with Scipy equations. A normalized vector with the above problem is showed to correct it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from scipy.spatial.distance import jaccard as jaccard_scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine(vec_sent1_tfidf,vec_sent2_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line result in an error because used vectors are bow vectors in the following format: list((word_id,word_tfidf_coef)). Then a previous transformation of vectors is needed to 1D numerical vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.787652089532131, 0.0, 0.3727987817044736, 0.49053568087890215] \n",
      " [0.5599326515327857, 0.5721809582593161, 0.4817709603680243, 0.0, 0.35634410125465255]\n"
     ]
    }
   ],
   "source": [
    "from six import iteritems\n",
    "vec2 = dict(vec_sent1_tfidf)\n",
    "vec1 = dict(vec_sent2_tfidf)\n",
    "#[vec1.get(index, 0.0)**2 for index, value in iteritems(vec2)]\n",
    "nvec1,nvec2 = [],[]\n",
    "words = set(vec1.keys()).union(vec2.keys())\n",
    "for word in words:\n",
    "    nvec1.append(vec1.get(word,0.0))\n",
    "    nvec2.append(vec2.get(word,0.0))\n",
    "print(nvec1,'\\n',nvec2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scipy Cosine: 0.37452097630042125\n",
      "Scipy Jaccard: 1.0\n"
     ]
    }
   ],
   "source": [
    "print('Scipy Cosine:',cosine(nvec1,nvec2))\n",
    "print('Scipy Jaccard:',jaccard_scipy(nvec1,nvec2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Textsim TfIdf-Jaccard sentence similarity\n",
    "\n",
    "Doing similarity with textsim package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/abelm')\n",
    "\n",
    "from textsim.tokendists import jaccard_distance\n",
    "from textsim.tokendists import cosine_similarity_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Textsim Jaccard 0.625\n",
      "TfIdf Textsim Jaccard 0.875\n",
      "Textsim Cosine Sklearn 0.3333333333333334\n"
     ]
    }
   ],
   "source": [
    "print('Textsim Jaccard', jaccard_distance(sent1,sent2))\n",
    "print('TfIdf Textsim Jaccard', jaccard_distance(nvec1,nvec2))\n",
    "#Prerocessed sentences\n",
    "print('Textsim Cosine Sklearn',cosine_similarity_sklearn('girl run hall','Alice eat hall'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both values need to be string objects or numerical vectors!\n",
      "TfIdf Textsim Cosine Sklearn 0.625479023699579\n"
     ]
    }
   ],
   "source": [
    "A = np.asarray(nvec1).reshape((1,-1))\n",
    "B = np.asarray(nvec2).reshape((1,-1))\n",
    "\n",
    "print('TfIdf Textsim Cosine Sklearn',cosine_similarity_sklearn(A,B))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Best Pair Word Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Gensim TfIdf-Hellinger sentence similarity\n",
    "\n",
    "Testing similarity with Gensim ecuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.matutils import kullback_leibler, jaccard, hellinger, cossim\n",
    "\n",
    "print('Gensim Hellinger',hellinger(vec_sent1_tfidf,vec_sent2_tfidf))\n",
    "print('Gensim Cosine:',cossim(vec_sent1_tfidf,vec_sent2_tfidf))\n",
    "print('Gensim Jaccard:',jaccard(vec_sent1_tfidf,vec_sent2_tfidf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One problem with Hellinger equation in Gensim is that iterates over the major vector, then in the above example the word 74333(eat) never will affect the result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "* 0.659 input = bowvec, Hellinger, Gensim, \n",
    "* 0.267 input = bowvec, Cosine, Gensim\n",
    "* 0.839 input = bowvec, Jaccard, Gensim\n",
    "* 0.732 input = tfidf vec, Cosine, Scipy\n",
    "* 1.000 input = tfidf vec, Jaccard, Scipy\n",
    "* 0.777 input = str, Jaccard, Textsim, stopwords_filter=no\n",
    "* 0.800 input = str, Jaccard, Textsim, stopwords_filter=yes\n",
    "* 0.333 input = str, Cosine, Textsim-sklearn, stopwords_filter=yes\n",
    "* 0.433 input = str, Cosine, Textsim-sklearn, stopwords_filter=no\n",
    "* 0.267 input = tfidf vec, Cosine, Sklearn\n",
    "\n",
    "As you can self analyze Gensim and Sklearn cosine have the same result. The sentences have words in common and in the context of \"Alice's Adventures in Wonderland\" by Lewis Carroll have the same mining, this book is part of the Gutenberg collection but only appears on Wikipedia dump as articles of few importance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
