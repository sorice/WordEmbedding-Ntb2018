{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GlobVe Model\n",
    "\n",
    "*Glove+Gensim software example.*\n",
    "\n",
    "**Install:**\n",
    "pip install glove_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glove import Corpus, Glove\n",
    "import gensim\n",
    "from six import iteritems\n",
    "from gensim.corpora import TextCorpus, MmCorpus, Dictionary\n",
    "import time\n",
    "import nltk\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrangling Data\n",
    "\n",
    "From txt to iterable of lists of strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_collection = []\n",
    "file_path = 'gutenberg/'\n",
    "file_list = list(os.popen('ls '+ file_path).read().split('\\n'))\n",
    "for file in file_list:\n",
    "    if file:\n",
    "        with open(os.path.join(file_path,file)) as doc:\n",
    "            doc_collection.append(doc.read())\n",
    "            \n",
    "#Wrangling the data from list of doc-strings -> list of word-list by sentences\n",
    "sentences = []\n",
    "for doc in range(len(doc_collection)):\n",
    "    for sent in nltk.sent_tokenize(doc_collection[doc]):\n",
    "        sent_words = []\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            sent_words.append(word)\n",
    "        sentences.append(sent_words)\n",
    "            \n",
    "# load nltk's English stopwords as variable called 'stopwords'\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "texts = [[word for word in sentence if word not in stopwords] for sentence in sentences]\n",
    "\n",
    "id2word = gensim.corpora.Dictionary(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_model = Corpus()\n",
    "corpus_model.fit(texts, window=10)\n",
    "corpus_model.save('gensim_data/glove_Gutenberg_corpus.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 0 training epochs with 2 threads\n"
     ]
    }
   ],
   "source": [
    "glove = Glove(no_components=300, learning_rate=0.05)\n",
    "glove.fit(corpus_model.matrix, epochs=0, no_threads=2, verbose=True)\n",
    "glove.add_dictionary(corpus_model.dictionary)\n",
    "glove.save('gensim_data/glove_Gutenberg.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00125988, -0.00017377, -0.0013515 , -0.00076598,  0.00116861,\n",
       "        0.00132032, -0.00076594, -0.00147921,  0.00148966, -0.00104364])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Showing a word vector, dictionary-key is needed\n",
    "glove.word_vectors[glove.dictionary['girl']][:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sklearn GlobVe-Cosine sentence similarity\n",
    "\n",
    "### Wrangling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = 'the girl run into the hall'\n",
    "sentence2 = 'Here Alice run to the hall'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def preproc_data(sent1, sent2, model):\n",
    "    sentence1 = sent1.split()\n",
    "    sentence2 = sent2.split()\n",
    "\n",
    "    globvec_sent1 = []\n",
    "    globvec_sent2 = []\n",
    "\n",
    "    for word in sentence1:\n",
    "        try:\n",
    "            glove.dictionary[word]\n",
    "            globvec_sent1.append(glove.word_vectors[glove.dictionary[word]])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    for word in sentence2:\n",
    "        try:\n",
    "            glove.dictionary[word]\n",
    "            globvec_sent2.append(glove.word_vectors[glove.dictionary[word]])\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "    globvec_sent1 = sum(np.asarray(globvec_sent1))\n",
    "    globvec_sent2 = sum(np.asarray(globvec_sent2))\n",
    "    \n",
    "    A = globvec_sent1.reshape(1,-1)\n",
    "    B = globvec_sent2.reshape(1,-1)\n",
    "    \n",
    "    return A, B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 300)\n",
      "[-0.00414174  0.0023383   0.00038274  0.00010886  0.00302493  0.00504701\n",
      " -0.00417027 -0.00191416 -0.00218303 -0.00053421]\n"
     ]
    }
   ],
   "source": [
    "globvec_sent1, globvec_sent2 = preproc_data(sentence1,sentence2,glove)\n",
    "print(globvec_sent1.shape)\n",
    "print(globvec_sent2[0][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.56943977206087759"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "cosine_similarity(globvec_sent1,globvec_sent2)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6269040226830056"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Filtering stopwords\n",
    "sent1s = 'girl run hall'\n",
    "sent2s = 'Alice run hall'\n",
    "globvec_sent1s, globvec_sent2s = preproc_data(sent1s,sent2s,glove)\n",
    "cosine_similarity(globvec_sent1s,globvec_sent2s)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scipy Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.430560227939\n",
      "0.373095977317\n"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import cosine as cosine_scipy\n",
    "\n",
    "print(cosine_scipy(globvec_sent1,globvec_sent2))\n",
    "print(cosine_scipy(globvec_sent1s,globvec_sent2s)) #Filtering stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glove transform_paragraph method\n",
    "\n",
    "Still remains experimental doesn't works.\n",
    "\n",
    "Other methods like Harmonic mean of word-similarity are not possible with this package because this methods are implemented in every Representation Text model in Gensim, but Gensim doesn't have an implementation of GloVe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "1. Like word2vec this model allows parallelism training.\n",
    "2. Like word2vec this model generates a vector for every word appearing in the corpus with length = 'no_components'.\n",
    "3. Applying cumulative sum of ndarrays it is possible to obtain a sentence vector of the same length.\n",
    "4. Then using a regular scipy, sklearn, textsim tokendist or vector similarity distance the similarity between 2 sentences is possible.\n",
    "5. Using this mechanism it is possible to reproduce some **word embedding features** used in Paraphrase Recognition task.\n",
    "6. Generate GlobVe model with English Wikipedia it is no possible in this computer (i7 8Gb RAM).\n",
    "\n",
    "# Recommendations\n",
    "\n",
    "- Test GlobVe with spanish wikipedia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
